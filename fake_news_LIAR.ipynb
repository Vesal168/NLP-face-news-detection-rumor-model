{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.34.0)Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.14.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (3.12.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.17.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (1.26.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2.28.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2022.9.13)\n",
      "Requirement already satisfied: fsspec in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.9.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2022.5.18.1)\n",
      "\n",
      "[notice] A new release of pip available: 22.1.2 -> 23.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_train = pd.read_csv(r\"E:\\Drive D\\MA-ICT Convergence\\Semester 3\\Courses\\NLP\\Fake News Detection BERT\\LIAR Dataset\\train.tsv\", sep=\"\\t\", header=None)\n",
    "data_valid = pd.read_csv(r\"E:\\Drive D\\MA-ICT Convergence\\Semester 3\\Courses\\NLP\\Fake News Detection BERT\\LIAR Dataset\\valid.tsv\", sep=\"\\t\", header=None)\n",
    "data_test = pd.read_csv(r\"E:\\Drive D\\MA-ICT Convergence\\Semester 3\\Courses\\NLP\\Fake News Detection BERT\\LIAR Dataset\\test.tsv\", sep=\"\\t\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2635.json</td>\n",
       "      <td>false</td>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>dwayne-bohac</td>\n",
       "      <td>State representative</td>\n",
       "      <td>Texas</td>\n",
       "      <td>republican</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a mailer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10540.json</td>\n",
       "      <td>half-true</td>\n",
       "      <td>When did the decline of coal start? It started...</td>\n",
       "      <td>energy,history,job-accomplishments</td>\n",
       "      <td>scott-surovell</td>\n",
       "      <td>State delegate</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>democrat</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a floor speech.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>324.json</td>\n",
       "      <td>mostly-true</td>\n",
       "      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n",
       "      <td>foreign-policy</td>\n",
       "      <td>barack-obama</td>\n",
       "      <td>President</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>democrat</td>\n",
       "      <td>70.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Denver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1123.json</td>\n",
       "      <td>false</td>\n",
       "      <td>Health care reform legislation is likely to ma...</td>\n",
       "      <td>health-care</td>\n",
       "      <td>blog-posting</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>7.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>a news release</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9028.json</td>\n",
       "      <td>half-true</td>\n",
       "      <td>The economic turnaround started at the end of ...</td>\n",
       "      <td>economy,jobs</td>\n",
       "      <td>charlie-crist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Florida</td>\n",
       "      <td>democrat</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>an interview on CNN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0            1                                                  2   \\\n",
       "0   2635.json        false  Says the Annies List political group supports ...   \n",
       "1  10540.json    half-true  When did the decline of coal start? It started...   \n",
       "2    324.json  mostly-true  Hillary Clinton agrees with John McCain \"by vo...   \n",
       "3   1123.json        false  Health care reform legislation is likely to ma...   \n",
       "4   9028.json    half-true  The economic turnaround started at the end of ...   \n",
       "\n",
       "                                   3               4                     5   \\\n",
       "0                            abortion    dwayne-bohac  State representative   \n",
       "1  energy,history,job-accomplishments  scott-surovell        State delegate   \n",
       "2                      foreign-policy    barack-obama             President   \n",
       "3                         health-care    blog-posting                   NaN   \n",
       "4                        economy,jobs   charlie-crist                   NaN   \n",
       "\n",
       "         6           7     8     9      10     11    12                   13  \n",
       "0     Texas  republican   0.0   1.0    0.0    0.0   0.0             a mailer  \n",
       "1  Virginia    democrat   0.0   0.0    1.0    1.0   0.0      a floor speech.  \n",
       "2  Illinois    democrat  70.0  71.0  160.0  163.0   9.0               Denver  \n",
       "3       NaN        none   7.0  19.0    3.0    5.0  44.0       a news release  \n",
       "4   Florida    democrat  15.0   9.0   20.0   19.0   2.0  an interview on CNN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Viewing sample train data before preprocessing\n",
    "data_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11972.json</td>\n",
       "      <td>true</td>\n",
       "      <td>Building a wall on the U.S.-Mexico border will...</td>\n",
       "      <td>immigration</td>\n",
       "      <td>rick-perry</td>\n",
       "      <td>Governor</td>\n",
       "      <td>Texas</td>\n",
       "      <td>republican</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>42</td>\n",
       "      <td>23</td>\n",
       "      <td>18</td>\n",
       "      <td>Radio interview</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11685.json</td>\n",
       "      <td>false</td>\n",
       "      <td>Wisconsin is on pace to double the number of l...</td>\n",
       "      <td>jobs</td>\n",
       "      <td>katrina-shankland</td>\n",
       "      <td>State representative</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>democrat</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>a news conference</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11096.json</td>\n",
       "      <td>false</td>\n",
       "      <td>Says John McCain has done nothing to help the ...</td>\n",
       "      <td>military,veterans,voting-record</td>\n",
       "      <td>donald-trump</td>\n",
       "      <td>President-Elect</td>\n",
       "      <td>New York</td>\n",
       "      <td>republican</td>\n",
       "      <td>63</td>\n",
       "      <td>114</td>\n",
       "      <td>51</td>\n",
       "      <td>37</td>\n",
       "      <td>61</td>\n",
       "      <td>comments on ABC's This Week.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5209.json</td>\n",
       "      <td>half-true</td>\n",
       "      <td>Suzanne Bonamici supports a plan that will cut...</td>\n",
       "      <td>medicare,message-machine-2012,campaign-adverti...</td>\n",
       "      <td>rob-cornilles</td>\n",
       "      <td>consultant</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>republican</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>a radio show</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9524.json</td>\n",
       "      <td>pants-fire</td>\n",
       "      <td>When asked by a reporter whether hes at the ce...</td>\n",
       "      <td>campaign-finance,legal-issues,campaign-adverti...</td>\n",
       "      <td>state-democratic-party-wisconsin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>democrat</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>a web video</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0           1                                                  2   \\\n",
       "0  11972.json        true  Building a wall on the U.S.-Mexico border will...   \n",
       "1  11685.json       false  Wisconsin is on pace to double the number of l...   \n",
       "2  11096.json       false  Says John McCain has done nothing to help the ...   \n",
       "3   5209.json   half-true  Suzanne Bonamici supports a plan that will cut...   \n",
       "4   9524.json  pants-fire  When asked by a reporter whether hes at the ce...   \n",
       "\n",
       "                                                  3   \\\n",
       "0                                        immigration   \n",
       "1                                               jobs   \n",
       "2                    military,veterans,voting-record   \n",
       "3  medicare,message-machine-2012,campaign-adverti...   \n",
       "4  campaign-finance,legal-issues,campaign-adverti...   \n",
       "\n",
       "                                 4                     5          6   \\\n",
       "0                        rick-perry              Governor      Texas   \n",
       "1                 katrina-shankland  State representative  Wisconsin   \n",
       "2                      donald-trump       President-Elect   New York   \n",
       "3                     rob-cornilles            consultant     Oregon   \n",
       "4  state-democratic-party-wisconsin                   NaN  Wisconsin   \n",
       "\n",
       "           7   8    9   10  11  12                            13  \n",
       "0  republican  30   30  42  23  18               Radio interview  \n",
       "1    democrat   2    1   0   0   0             a news conference  \n",
       "2  republican  63  114  51  37  61  comments on ABC's This Week.  \n",
       "3  republican   1    1   3   1   1                  a radio show  \n",
       "4    democrat   5    7   2   2   7                   a web video  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Viewing sample train data before preprocessing\n",
    "data_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12134.json</td>\n",
       "      <td>barely-true</td>\n",
       "      <td>We have less Americans working now than in the...</td>\n",
       "      <td>economy,jobs</td>\n",
       "      <td>vicky-hartzler</td>\n",
       "      <td>U.S. Representative</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>republican</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>an interview with ABC17 News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>238.json</td>\n",
       "      <td>pants-fire</td>\n",
       "      <td>When Obama was sworn into office, he DID NOT u...</td>\n",
       "      <td>obama-birth-certificate,religion</td>\n",
       "      <td>chain-email</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>11</td>\n",
       "      <td>43</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>105</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7891.json</td>\n",
       "      <td>false</td>\n",
       "      <td>Says Having organizations parading as being so...</td>\n",
       "      <td>campaign-finance,congress,taxes</td>\n",
       "      <td>earl-blumenauer</td>\n",
       "      <td>U.S. representative</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>democrat</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>a U.S. Ways and Means hearing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8169.json</td>\n",
       "      <td>half-true</td>\n",
       "      <td>Says nearly half of Oregons children are poor.</td>\n",
       "      <td>poverty</td>\n",
       "      <td>jim-francesconi</td>\n",
       "      <td>Member of the State Board of Higher Education</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>an opinion article</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>929.json</td>\n",
       "      <td>half-true</td>\n",
       "      <td>On attacks by Republicans that various program...</td>\n",
       "      <td>economy,stimulus</td>\n",
       "      <td>barack-obama</td>\n",
       "      <td>President</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>democrat</td>\n",
       "      <td>70</td>\n",
       "      <td>71</td>\n",
       "      <td>160</td>\n",
       "      <td>163</td>\n",
       "      <td>9</td>\n",
       "      <td>interview with CBS News</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0            1                                                  2   \\\n",
       "0  12134.json  barely-true  We have less Americans working now than in the...   \n",
       "1    238.json   pants-fire  When Obama was sworn into office, he DID NOT u...   \n",
       "2   7891.json        false  Says Having organizations parading as being so...   \n",
       "3   8169.json    half-true     Says nearly half of Oregons children are poor.   \n",
       "4    929.json    half-true  On attacks by Republicans that various program...   \n",
       "\n",
       "                                 3                4   \\\n",
       "0                      economy,jobs   vicky-hartzler   \n",
       "1  obama-birth-certificate,religion      chain-email   \n",
       "2   campaign-finance,congress,taxes  earl-blumenauer   \n",
       "3                           poverty  jim-francesconi   \n",
       "4                  economy,stimulus     barack-obama   \n",
       "\n",
       "                                              5         6           7   8   \\\n",
       "0                            U.S. Representative  Missouri  republican   1   \n",
       "1                                            NaN       NaN        none  11   \n",
       "2                            U.S. representative    Oregon    democrat   0   \n",
       "3  Member of the State Board of Higher Education    Oregon        none   0   \n",
       "4                                      President  Illinois    democrat  70   \n",
       "\n",
       "   9    10   11   12                             13  \n",
       "0   0    1    0    0   an interview with ABC17 News  \n",
       "1  43    8    5  105                            NaN  \n",
       "2   1    1    1    0  a U.S. Ways and Means hearing  \n",
       "3   1    1    1    0             an opinion article  \n",
       "4  71  160  163    9        interview with CBS News  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Viewing sample train data before preprocessing\n",
    "data_valid.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Below function performs all the required data cleaning and preprocessing steps\n",
    "\n",
    "def data_preprocessing(dataset):\n",
    "  #Creating new column called 'label' with 1 for true and mostly-true values, else 0 i.e. 1=real, 0=fake\n",
    "  dataset['label']=[1 if x==\"true\"or x==\"mostly-true\" else 0 for x in dataset[1]] \n",
    "  #Dropping unwanted columns\n",
    "  dataset = dataset.drop(labels=[0,1,8,9,10,11,12] ,axis=1)\n",
    "  #Dealing with empty datapoints for metadata columns - subject, speaker, job, state,affiliation, context\n",
    "  meta = []\n",
    "  for i in range(len(dataset)):\n",
    "      subject = dataset[3][i]\n",
    "      if subject == 0:\n",
    "          subject = 'None'\n",
    "\n",
    "      speaker =  dataset[4][i]\n",
    "      if speaker == 0:\n",
    "          speaker = 'None'\n",
    "\n",
    "      job =  dataset[5][i]\n",
    "      if job == 0:\n",
    "          job = 'None'\n",
    "\n",
    "      state =  dataset[6][i]\n",
    "      if state == 0:\n",
    "          state = 'None'\n",
    "\n",
    "      affiliation =  dataset[7][i]\n",
    "      if affiliation == 0:\n",
    "          affiliation = 'None'\n",
    "\n",
    "      context =  dataset[13][i]\n",
    "      if context == 0 :\n",
    "          context = 'None'\n",
    "\n",
    "      meta.append(str(subject) + ' ' + str(speaker) + ' ' + str(job) + ' ' + str(state) + ' ' + str(affiliation) + ' ' + str(context)) #combining all the meta data columns into a single column\n",
    "  \n",
    "  #Adding cleaned and combined metadata column to the dataset\n",
    "  dataset[14] = meta\n",
    "  dataset[\"sentence\"] = dataset[14].astype('str')+\" \"+dataset[2] #Combining metadata and the text columns into single columns\n",
    "\n",
    "  dataset = dataset.drop([2,3,4,5,6,7,13,14], axis=1) #dropping metadata columns, as we have merged them into a single column\n",
    "  dataset.dropna() #Dropping if there are still any null values\n",
    "\n",
    "  return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying pre-processing to the raw data - train, valid and test sets\n",
    "data_train = data_preprocessing(data_train)\n",
    "data_valid = data_preprocessing(data_valid)\n",
    "data_test = data_preprocessing(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>abortion dwayne-bohac State representative Tex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>energy,history,job-accomplishments scott-surov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>foreign-policy barack-obama President Illinois...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>health-care blog-posting nan nan none a news r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>economy,jobs charlie-crist nan Florida democra...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                           sentence\n",
       "0      0  abortion dwayne-bohac State representative Tex...\n",
       "1      0  energy,history,job-accomplishments scott-surov...\n",
       "2      1  foreign-policy barack-obama President Illinois...\n",
       "3      0  health-care blog-posting nan nan none a news r...\n",
       "4      0  economy,jobs charlie-crist nan Florida democra..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sample data after preprocessing\n",
    "data_train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing the distribtuion of labels in each dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    6602\n",
       "1    3638\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    864\n",
       "1    420\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_valid['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    818\n",
       "1    449\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that all the datasets have almost equal distribution of real and fake categories\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Analyzing length of sentences in training data to decide on MAX_LENGTH variable, which is required for BERT and RoBERTa\n",
    "\n",
    "sent_len = []\n",
    "for sent in data_train['sentence']:\n",
    "  sent_len.append(len(sent))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize =(10, 7))\n",
    "plt.boxplot(sent_len)\n",
    "plt.show()\n",
    "\n",
    "sent_len = [i for i in sent_len if i<=500] #Excluding the outliers\n",
    "fig2 = plt.figure(figsize =(10, 7))\n",
    "plt.hist(sent_len, 5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above histogram, we can see that, majority of the sentences are in the range of 150-250 and most of the sentences length is less than 350\n",
    "\n",
    "Installing required library - transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#importing required packages  \n",
    "from transformers import (\n",
    "    BertForSequenceClassification,    \n",
    "    BertTokenizer,\n",
    "    RobertaForSequenceClassification,\n",
    "    RobertaTokenizer,\n",
    "    AdamW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base models loaded\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if CUDA is available, if not, use CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Loading BERT base model\n",
    "bert_model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", \n",
    "                                                           num_labels=2, \n",
    "                                                           output_attentions=False, \n",
    "                                                           output_hidden_states=False)\n",
    "bert_model.to(device)\n",
    "\n",
    "# BERT tokenizer\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case=True)\n",
    "\n",
    "# Loading RoBERTa base model\n",
    "roberta_model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\", \n",
    "                                                                 num_labels=2, \n",
    "                                                                 output_attentions=False, \n",
    "                                                                 output_hidden_states=False)\n",
    "roberta_model.to(device)\n",
    "\n",
    "# RoBERTa tokenizer\n",
    "roberta_tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\", do_lower_case=True)\n",
    "\n",
    "print('Base models loaded')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demonstrating how BERT and RoBERTa tokenizers work on a sample sentence\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  abortion dwayne-bohac State representative Texas republican a mailer Says the Annies List political group supports third-trimester abortions on demand.\n",
      "Tokenized BERT:  ['abortion', 'd', '##way', '##ne', '-', 'bo', '##ha', '##c', 'state', 'representative', 'texas', 'republican', 'a', 'mail', '##er', 'says', 'the', 'annie', '##s', 'list', 'political', 'group', 'supports', 'third', '-', 'trim', '##ester', 'abortion', '##s', 'on', 'demand', '.']\n",
      "Token IDs BERT:  [11324, 1040, 4576, 2638, 1011, 8945, 3270, 2278, 2110, 4387, 3146, 3951, 1037, 5653, 2121, 2758, 1996, 8194, 2015, 2862, 2576, 2177, 6753, 2353, 1011, 12241, 20367, 11324, 2015, 2006, 5157, 1012]\n",
      "Tokenized RoBERTa:  ['abortion', 'Ġd', 'wayne', '-', 'b', 'oh', 'ac', 'ĠState', 'Ġrepresentative', 'ĠTexas', 'Ġrepublican', 'Ġa', 'Ġmail', 'er', 'ĠSays', 'Ġthe', 'ĠAnn', 'ies', 'ĠList', 'Ġpolitical', 'Ġgroup', 'Ġsupports', 'Ġthird', '-', 'tr', 'imester', 'Ġabortions', 'Ġon', 'Ġdemand', '.']\n",
      "Token IDs RoBERTa:  [27275, 385, 20143, 12, 428, 2678, 1043, 331, 4915, 1184, 37958, 10, 7107, 254, 15674, 5, 3921, 918, 9527, 559, 333, 4548, 371, 12, 4328, 38417, 17600, 15, 1077, 4]\n"
     ]
    }
   ],
   "source": [
    "# Print the original sentence.\n",
    "print('Original: ', data_train[\"sentence\"][0])\n",
    "\n",
    "# Split the sentence into tokens - BERT\n",
    "print('Tokenized BERT: ', bert_tokenizer.tokenize(data_train[\"sentence\"][0]))\n",
    "\n",
    "# Mapping tokens to token IDs - BERT\n",
    "print('Token IDs BERT: ', bert_tokenizer.convert_tokens_to_ids(bert_tokenizer.tokenize(data_train[\"sentence\"][0])))\n",
    "\n",
    "# Split the sentence into tokens - RoBERTa\n",
    "print('Tokenized RoBERTa: ', roberta_tokenizer.tokenize(data_train[\"sentence\"][0]))\n",
    "\n",
    "# Mapping tokens to token IDs - RoBERTa\n",
    "print('Token IDs RoBERTa: ', roberta_tokenizer.convert_tokens_to_ids(roberta_tokenizer.tokenize(data_train[\"sentence\"][0])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assigning sentences and labels to separate variables\n",
    "sentences = data_train[\"sentence\"].values\n",
    "labels = data_train[\"label\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Below function performs tokenization process as required by bert and roberta models, for a given dataset\n",
    "def bert_robert_tokenization(dataset):\n",
    "  sentences = dataset[\"sentence\"].values\n",
    "  labels = dataset[\"label\"].values\n",
    "  max_length = 256\n",
    "\n",
    "  # Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "  bert_input_ids = []\n",
    "  bert_attention_masks = []\n",
    "  roberta_input_ids = []\n",
    "  roberta_attention_masks = []\n",
    "\n",
    "  sentence_ids = []\n",
    "  counter = 0\n",
    "\n",
    "  # For every sentence...\n",
    "  for sent in sentences:\n",
    "      #encode_plus function will encode the sentences as required by model, including tokenization process and mapping token ids\n",
    "      bert_encoded_dict = bert_tokenizer.encode_plus(\n",
    "                          str(sent),        #sentence              \n",
    "                          add_special_tokens = True, # Add '[CLS]' and '[SEP]' tokens \n",
    "                          max_length = 256,     #Since we have seen from our analysis that majority of sentences have length less than 300.    \n",
    "                          pad_to_max_length = True,    # Pad sentences to 256 length  if the length of sentence is less than max_length\n",
    "                          return_attention_mask = True,   # Create attention mask\n",
    "                          truncation = True,  # truncate sentences to 256 length  if the length of sentence is greater than max_length\n",
    "                          return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                    )\n",
    "      \n",
    "      roberta_encoded_dict = roberta_tokenizer.encode_plus(\n",
    "                          str(sent),        #sentence\n",
    "                          add_special_tokens = True, # Add '[CLS]' and '[SEP]' tokens \n",
    "                          max_length = 256,        #Since we have seen from our analysis that majority of sentences have length less than 300.   \n",
    "                          pad_to_max_length = True,     # Pad sentences to 256 length  if the length of sentence is less than max_length\n",
    "                          return_attention_mask = True,   # Create attention mask\n",
    "                          truncation = True,   # truncate sentences to 256 length  if the length of sentence is greater than max_length\n",
    "                          return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                    )\n",
    "      \n",
    "    \n",
    "      # Add the encoded sentence to the list.    \n",
    "      bert_input_ids.append(bert_encoded_dict['input_ids'])\n",
    "      roberta_input_ids.append(roberta_encoded_dict['input_ids'])\n",
    "      \n",
    "      \n",
    "      # Add attention mask to the list \n",
    "      bert_attention_masks.append(bert_encoded_dict['attention_mask'])\n",
    "      roberta_attention_masks.append(roberta_encoded_dict['attention_mask'])\n",
    "      \n",
    "      \n",
    "      # collecting sentence_ids\n",
    "      sentence_ids.append(counter)\n",
    "      counter  = counter + 1\n",
    "      \n",
    "      \n",
    "      \n",
    "  # Convert the lists into tensors.\n",
    "  bert_input_ids = torch.cat(bert_input_ids, dim=0)\n",
    "  bert_attention_masks = torch.cat(bert_attention_masks, dim=0)\n",
    "\n",
    "  roberta_input_ids = torch.cat(roberta_input_ids, dim=0)\n",
    "  roberta_attention_masks = torch.cat(roberta_attention_masks, dim=0)\n",
    "\n",
    "\n",
    "  labels = torch.tensor(labels)\n",
    "  sentence_ids = torch.tensor(sentence_ids)\n",
    "\n",
    "  return {\"Bert\":[bert_input_ids, bert_attention_masks, labels], \"Roberta\":[roberta_input_ids, roberta_attention_masks, labels]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2622: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, random_split\n",
    "# function to seed the script globally\n",
    "torch.manual_seed(0)\n",
    "\n",
    "#tokenizing train set\n",
    "token_dict_train = bert_robert_tokenization(data_train)\n",
    "\n",
    "bert_input_ids,bert_attention_masks,labels = token_dict_train[\"Bert\"]\n",
    "roberta_input_ids, roberta_attention_masks, labels = token_dict_train[\"Roberta\"]\n",
    "\n",
    "#tokenizing validation set\n",
    "token_dict_valid = bert_robert_tokenization(data_valid)\n",
    "\n",
    "bert_input_ids_valid,bert_attention_masks_valid,labels_valid = token_dict_valid[\"Bert\"]\n",
    "roberta_input_ids_valid, roberta_attention_masks_valid, labels_valid = token_dict_valid[\"Roberta\"]\n",
    "\n",
    "#tokenizing test set\n",
    "token_dict_test = bert_robert_tokenization(data_test)\n",
    "\n",
    "bert_input_ids_test,bert_attention_masks_test,labels_test = token_dict_test[\"Bert\"]\n",
    "roberta_input_ids_test, roberta_attention_masks_test, labels_test = token_dict_test[\"Roberta\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the training inputs into a TensorDataset.\n",
    "bert_train_dataset = TensorDataset( bert_input_ids, bert_attention_masks, labels) \n",
    "roberta_train_dataset = TensorDataset(roberta_input_ids, roberta_attention_masks, labels)\n",
    "\n",
    "# Combine the validation inputs into a TensorDataset.\n",
    "bert_val_dataset = TensorDataset(bert_input_ids_valid,bert_attention_masks_valid,labels_valid)\n",
    "roberta_val_dataset = TensorDataset(roberta_input_ids_valid, roberta_attention_masks_valid, labels_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the test inputs into a TensorDataset.\n",
    "bert_test_dataset = TensorDataset(bert_input_ids_test,bert_attention_masks_test,labels_test)\n",
    "roberta_test_dataset = TensorDataset(roberta_input_ids_test, roberta_attention_masks_test, labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# Create the DataLoaders for our training - Loads the data randomly in batches of size 32\n",
    "bert_train_dataloader = DataLoader(\n",
    "            bert_train_dataset,  # The training samples.\n",
    "            sampler = RandomSampler(bert_train_dataset), # Select batches randomly\n",
    "            batch_size = batch_size # Trains with this batch size.\n",
    "        )\n",
    "\n",
    "roberta_train_dataloader = DataLoader(\n",
    "            roberta_train_dataset,  # The training samples.\n",
    "            sampler = RandomSampler(roberta_train_dataset), # Select batches randomly\n",
    "            batch_size = batch_size # Trains with this batch size.\n",
    "        )\n",
    "\n",
    "# Create the DataLoaders for our validation - Loads the data in batches of size 32\n",
    "bert_validation_dataloader = DataLoader(\n",
    "            bert_val_dataset, # The validation samples.\n",
    "            sampler = SequentialSampler(bert_val_dataset), # Pull out batches sequentially.\n",
    "            batch_size = batch_size # Evaluate with this batch size.\n",
    "        )\n",
    "\n",
    "\n",
    "roberta_validation_dataloader = DataLoader(\n",
    "            roberta_val_dataset, # The validation samples.\n",
    "            sampler = SequentialSampler(roberta_val_dataset), # Pull out batches sequentially.\n",
    "            batch_size = batch_size # Evaluate with this batch size.\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizers - AdamW\n",
    "# here, i have used default learning rate and epsilon values for both BERT and RoBERTa\n",
    "bert_optimizer = AdamW(bert_model.parameters(),\n",
    "                  lr = 5e-5, \n",
    "                  eps = 1e-8,\n",
    "                  no_deprecation_warning=True\n",
    "                )\n",
    "\n",
    "roberta_optimizer = AdamW(roberta_model.parameters(),\n",
    "                  lr = 5e-5, \n",
    "                  eps = 1e-8,\n",
    "                  no_deprecation_warning=True\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Number of training epochs\n",
    "epochs = 2\n",
    "\n",
    "# Total number of training steps is [number of batches] x [number of epochs]\n",
    "total_steps = len(bert_train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "bert_scheduler = get_linear_schedule_with_warmup(bert_optimizer, \n",
    "                                            num_warmup_steps = 0, \n",
    "                                            num_training_steps = total_steps)\n",
    "\n",
    "roberta_scheduler = get_linear_schedule_with_warmup(roberta_optimizer, \n",
    "                                            num_warmup_steps = 0,\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, using the CPU instead.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# tell pytorch to use the gpu if available\n",
    "if torch.cuda.is_available():    \n",
    "      \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BERT - Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 2 ========\n",
      "Training...\n",
      "  Batch    40  of    320.    Time used: 0:23:33.\n",
      "  Batch    80  of    320.    Time used: 0:47:00.\n",
      "  Batch   120  of    320.    Time used: 1:09:12.\n",
      "  Batch   160  of    320.    Time used: 1:29:45.\n",
      "  Batch   200  of    320.    Time used: 1:55:01.\n",
      "  Batch   240  of    320.    Time used: 2:22:57.\n",
      "  Batch   280  of    320.    Time used: 2:51:53.\n",
      "\n",
      "  Average training loss: 0.63\n",
      "  Training epcoh took: 3:21:18\n",
      "\n",
      "Validation...\n",
      "  Accuracy: 0.70\n",
      "  Validation took: 0:09:22\n",
      "\n",
      "======== Epoch 2 / 2 ========\n",
      "Training...\n",
      "  Batch    40  of    320.    Time used: 0:30:23.\n",
      "  Batch    80  of    320.    Time used: 1:00:23.\n",
      "  Batch   120  of    320.    Time used: 1:32:02.\n",
      "  Batch   160  of    320.    Time used: 2:05:38.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "seed_val = 42\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "loss_values = []\n",
    "for epoch_i in range(0, epochs):\n",
    "    #Training \n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_loss = 0\n",
    "    bert_model.train()\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(bert_train_dataloader):\n",
    "      #Report progress after every 40 epochs\n",
    "        if step % 40 == 0 and not step == 0: \n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            # print current training batch and elapsed time\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Time used: {:}.'.format(step, len(bert_train_dataloader), elapsed))\n",
    "        \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        \n",
    "        bert_model.zero_grad()        \n",
    "        \n",
    "        outputs = bert_model(b_input_ids, \n",
    "                    token_type_ids=None, \n",
    "                    attention_mask=b_input_mask, \n",
    "                    labels=b_labels)\n",
    "        \n",
    "        # model returns a tuple, extract loss value from that tuple\n",
    "        loss = outputs[0]\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(bert_model.parameters(), 1.0)\n",
    "        bert_optimizer.step()\n",
    "        \n",
    "        bert_scheduler.step()\n",
    "    # Calculate the average loss over the training data.\n",
    "    avg_train_loss = total_loss / len(bert_train_dataloader)            \n",
    "    \n",
    "    # Store the loss value for plotting the learning curve.\n",
    "    loss_values.append(avg_train_loss)\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
    "        \n",
    "    #Validation Part\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Validation...\")\n",
    "    t0 = time.time()\n",
    "    # Put the model in evaluation mode    \n",
    "    bert_model.eval()\n",
    "    # Tracking variables \n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in bert_validation_dataloader:\n",
    "        \n",
    "        # Add batch to GPU\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        \n",
    "        # Unpack the inputs from our dataloader\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        \n",
    "        with torch.no_grad():        \n",
    "           outputs = bert_model(b_input_ids, \n",
    "                            token_type_ids=None, \n",
    "                            attention_mask=b_input_mask)\n",
    "        \n",
    "        logits = outputs[0]\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        \n",
    "        # Calculate the accuracy for this batch of test sentences.\n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "        \n",
    "        # Accumulate the total accuracy.\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "        # Track the number of batches\n",
    "        nb_eval_steps += 1\n",
    "    # Report the final accuracy for this validation run.\n",
    "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
    "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
    "print(\"\")\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "\n",
    "# Calculate predicted labels\n",
    "predicted_labels.extend(np.argmax(logits, axis=1))\n",
    "\n",
    "# Calculate true labels\n",
    "true_labels.extend(label_ids)\n",
    "\n",
    "# Generate the confusion matrix\n",
    "confusion = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
